{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "test",
            "type": "debugpy",
            "request": "launch",
            // "program": "torchrun example_text_completion.py",
            "console": "integratedTerminal",
            "module": "torch.distributed.run",
            "justMyCode": true,
            // "env": {
            //     "NCCL_P2P_DISABLE": "1",
            //     "NCCL_IB_DISABLE": "1",
            //     "CUDA_DEVICE_MAX_CONNECTIONS": "2",
            //     "CUDA_VISIBLE_DEVICES": "1,3"
            // },
            "args": [
                "--nproc_per_node",
                "1",
                "llama/model.py",
            ]
        },
        {
            "name": "LLaMa",
            "type": "debugpy",
            "request": "launch",
            // "program": "torchrun example_text_completion.py",
            "console": "integratedTerminal",
            "module": "torch.distributed.run",
            "justMyCode": true,
            // "env": {
            //     "NCCL_P2P_DISABLE": "1",
            //     "NCCL_IB_DISABLE": "1",
            //     "CUDA_DEVICE_MAX_CONNECTIONS": "2",
            //     "CUDA_VISIBLE_DEVICES": "1,3"
            // },
            "args": [
                "--nproc_per_node",
                "1",
                "example_text_completion.py",
                "--ckpt_dir",
                "${workspaceFolder}/llama-2-7b/",
                "--tokenizer_path",
                "${workspaceFolder}/tokenizer.model",
                "--max_seq_len",
                "128",
                "--max_batch_size",
                "5"
            ]
        }
    ]
}